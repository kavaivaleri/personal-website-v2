---
title: "Understanding Fun-Tuning: How Researchers Found a New Way to Hack AI Models"
description: "An explanation of how researchers discovered a systematic way to make AI models ignore their safety guardrails by exploiting fine-tuning APIs"
url: "https://learnprompting.org/blog/fun-tuning-prompt-hacking-gemini-by-exploiting-gemini-free-api"
publication: "Learn Prompting"
category: "Guide, AI Safety"
publishedAt: "2025-09-03"
featured: true
readTime: "1 min read"
---

An explanation of how researchers discovered a systematic way to make AI models ignore their safety guardrails by exploiting fine-tuning APIs