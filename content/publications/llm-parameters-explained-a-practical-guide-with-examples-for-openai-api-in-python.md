---
title: "LLM Parameters Explained: A Practical Guide with Examples for OpenAI API in Python"
description: "Edited a practical guide to the key parameters that control LLM behavior: temperature, top-p, max tokens, frequency and presence penalties, and stop sequences, explaining how each one affects randomness, coherence, length, repetition, and novelty, with concrete examples using OpenAI's ChatGPT and API so you can reliably steer outputs from deterministic to creative."
url: "https://learnprompting.org/blog/llm-parameters"
publication: "Learn Prompting"
category: "Guide, Prompt Engineering"
publishedAt: "2025-09-03"
featured: true
priority: "62"
readTime: "1 min read"
---
