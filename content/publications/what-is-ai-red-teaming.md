---
title: "What is AI Red Teaming?"
description: "Explore the key differences between prompt injection and jailbreaking in AI security."
url: "https://learnprompting.org/blog/what-is-ai-red-teaming"
publication: "Learn Prompting"
category: "Guide, AI Safety"
publishedAt: "2025-09-03"
featured: true
readTime: "1 min read"
---

Explore the key differences between prompt injection and jailbreaking in AI security.